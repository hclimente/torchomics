{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085e357-9672-4543-ad71-d463b2d0aba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from git import Repo\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from data import load, Dream\n",
    "from models import VaishnavCNN, SimpleCNN, fix_seeds\n",
    "from models.utils import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "repo = Repo(search_parent_directories=True)\n",
    "\n",
    "# save the current commit hash iff the repo has no un-committed changes\n",
    "sha = None if repo.is_dirty() else repo.head.object.hexsha\n",
    "\n",
    "if not sha:\n",
    "    warnings.warn(\"Uncommitted changes. The model parameters won't be saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d149d-ec57-4c92-aebf-a9075732b5e9",
   "metadata": {},
   "source": [
    "# Model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c2f7e-e6f7-4349-8fa1-0a2c437f5dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "n_epochs = 10\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "seed = 0\n",
    "\n",
    "fix_seeds(seed)\n",
    "\n",
    "# model specification\n",
    "net = SimpleCNN().to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f5790-6daf-4187-9092-b4fc15bd895a",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb19b2-f74d-4514-8457-808346d3ffe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation\n",
    "val_size = 10000\n",
    "\n",
    "tr_cached = \"train_dev.pt\" if device.type == \"cpu\" else \"train.pt\"\n",
    "tr = load(\"train_sequences.txt\", tr_cached, Dream, path=\"../data/dream\")\n",
    "tr, val = torch.utils.data.random_split(tr, [len(tr) - val_size, val_size])\n",
    "\n",
    "tr_loader = DataLoader(tr, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=val_size)\n",
    "\n",
    "# test (unlabelled)\n",
    "te = load(\"test_sequences.txt\", \"test.pt\", Dream, path=\"../data/dream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c765b-2bae-4d80-81aa-87704ef3c070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create a smaller training set for development\n",
    "# tr = load(\"train_sequences.txt\", tr_cached, Dream, path=\"../data/dream\")\n",
    "# tr, val = torch.utils.data.random_split(tr, [len(tr) - val_size, val_size])\n",
    "\n",
    "# d = Dream([''], [0])\n",
    "# d.sequences, d.rc_sequences, d.expression = next(iter(DataLoader(tr, batch_size=100000 + val_size, shuffle=True)))\n",
    "# d.expression = d.expression.flatten()\n",
    "\n",
    "# torch.save(d, '../data/dream/train_dev.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbf3bc-264c-4945-9967-4d8308803d8b",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50842a01-d3c4-4687-b89b-c2eec7a7cb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_losses = []\n",
    "val_losses = []\n",
    "\n",
    "val_seqs, val_rc, val_expression = next(iter(val_loader))\n",
    "# val_expression = val_expression[None, :].T\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    with tqdm(tr_loader) as tepoch:\n",
    "        for seq, rc, y in tepoch:\n",
    "\n",
    "            net.train()\n",
    "\n",
    "            seq, rc, y = seq.to(device), rc.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = net(seq)\n",
    "            tr_loss = criterion(y_pred, y)\n",
    "            tr_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tr_losses.append(tr_loss.item())\n",
    "\n",
    "            tepoch.set_postfix(\n",
    "                tr_loss=tr_loss.item(),\n",
    "                r=pearsonr(y, y_pred),\n",
    "                rho=spearmanr(y, y_pred),\n",
    "            )\n",
    "\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pred = net(val_seqs.to(device)).cpu()\n",
    "            val_loss = criterion(val_pred, val_expression)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "        # store model iff on a cuda environment and if the repo is clean\n",
    "        if device.type == \"cuda\" and sha:\n",
    "            net_name = net.__class__.__name__\n",
    "            torch.save(net.state_dict(), f\"../results/models/{net_name}.pt\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"commit\": sha,\n",
    "                    \"train_loss\": tr_losses,\n",
    "                    \"val_loss\": val_losses,\n",
    "                    \"val_r\": pearsonr(val_expression, val_pred),\n",
    "                    \"val_rho\": spearmanr(val_expression, val_pred),\n",
    "                },\n",
    "                f\"../results/models/{net_name}_stats.pt\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b26f7d-3189-4aec-9d49-0ba3893b6e9c",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875443c-ab65-47e0-adf1-f5834a6a7688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=val_expression.detach().numpy().flatten(), y=val_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b6453-126c-460c-8aa7-ab165732918f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.lineplot([i for i in range(len(tr_losses))], tr_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c54c61-9187-4f1c-aacf-bcd36e8faf2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.lineplot([i for i in range(len(val_losses))], val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee6928-cad7-4cad-a2ee-acaf0da3baeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
