{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085e357-9672-4543-ad71-d463b2d0aba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "import warnings\n",
    "\n",
    "from git import Repo\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from umap import UMAP\n",
    "\n",
    "from data import load, Dream, ReverseComplement\n",
    "from models import TransformerCNN, fix_seeds\n",
    "from models.utils import pearsonr, spearmanr, numpify\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 7.5]\n",
    "\n",
    "# save the current commit hash iff the repo has no un-committed changes\n",
    "repo = Repo(search_parent_directories=True)\n",
    "sha = None if repo.is_dirty() else repo.head.object.hexsha\n",
    "\n",
    "if not sha:\n",
    "    warnings.warn(\"Uncommitted changes. The model parameters won't be saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d149d-ec57-4c92-aebf-a9075732b5e9",
   "metadata": {},
   "source": [
    "# Model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c2f7e-e6f7-4349-8fa1-0a2c437f5dd5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "model_obj = TransformerCNN\n",
    "cuda_device = 0\n",
    "n_epochs = 10\n",
    "batch_size = 1024\n",
    "device = (\n",
    "    torch.device(f\"cuda:{cuda_device}\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "seed = 0\n",
    "\n",
    "# data transforms\n",
    "rc_transform = False\n",
    "\n",
    "fix_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30781db4-5530-4a2c-a62a-4c5df1f040b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model specification\n",
    "model = model_obj().to(device)\n",
    "model_name = model.__class__.__name__\n",
    "\n",
    "## initialize last layer's bias to the average\n",
    "model.fc[-1].bias = torch.nn.Parameter(torch.tensor(11.147))\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f5790-6daf-4187-9092-b4fc15bd895a",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb19b2-f74d-4514-8457-808346d3ffe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation\n",
    "val_size = 10000\n",
    "\n",
    "tr_cached = \"train_dev.pt\" if device.type == \"cpu\" else \"train.pt\"\n",
    "tr = load(\"train_sequences.txt\", tr_cached, Dream, path=here(\"data/dream\"))\n",
    "tr, val = torch.utils.data.random_split(tr, [len(tr) - val_size, val_size])\n",
    "\n",
    "val_loader = DataLoader(val, batch_size=val_size)\n",
    "val_seqs, val_rc, val_expression = next(iter(val_loader))\n",
    "\n",
    "# test (unlabelled)\n",
    "te = load(\"test_sequences.txt\", \"test.pt\", Dream, path=here(\"data/dream\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aebfa6-180a-4eaf-9698-15928c37edbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data transformations\n",
    "tf = []\n",
    "\n",
    "if rc_transform:\n",
    "    model_name += \"_t=rc\"\n",
    "\n",
    "tr.transforms = transforms.Compose(tf)\n",
    "tr_loader = DataLoader(tr, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c765b-2bae-4d80-81aa-87704ef3c070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create a smaller training set for development\n",
    "# tr = load(\"train_sequences.txt\", tr_cached, Dream, path=here(\"data/dream\"))\n",
    "# tr, val = torch.utils.data.random_split(tr, [len(tr) - val_size, val_size])\n",
    "\n",
    "# d = Dream([''], [0])\n",
    "# d.sequences, d.rc_sequences, d.expression = next(iter(DataLoader(tr, batch_size=100000 + val_size, shuffle=True)))\n",
    "# d.expression = d.expression.flatten()\n",
    "\n",
    "# torch.save(d, here('data/dream/train_dev.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bbf3bc-264c-4945-9967-4d8308803d8b",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50842a01-d3c4-4687-b89b-c2eec7a7cb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_losses = []\n",
    "val_losses = []\n",
    "tr_pearson = 0\n",
    "tr_spearman = 0\n",
    "\n",
    "# scaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    with tqdm(tr_loader) as tepoch:\n",
    "        for seq, rc, y in tepoch:\n",
    "\n",
    "            # forward\n",
    "            model.train()\n",
    "\n",
    "            seq, rc, y = seq.to(device), rc.to(device), y.to(device)\n",
    "\n",
    "            if rc_transform and random() < 0.5:\n",
    "                seq, rc = rc, seq\n",
    "\n",
    "            with torch.autocast(device_type=device.type):  # mixed precision\n",
    "                y_pred = model(seq, rc)\n",
    "                tr_loss = criterion(y_pred, y)\n",
    "\n",
    "            # backward (with mixed precision)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(tr_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # evaluation\n",
    "            model.eval()\n",
    "\n",
    "            tr_losses.append(tr_loss.item())\n",
    "            tr_pearson = 0.9 * tr_pearson + 0.1 * pearsonr(y, y_pred)\n",
    "            tr_spearman = 0.9 * tr_spearman + 0.1 * spearmanr(y, y_pred)\n",
    "\n",
    "            tepoch.set_postfix(\n",
    "                tr_loss=tr_loss.item(),\n",
    "                r=tr_pearson,\n",
    "                rho=tr_spearman,\n",
    "            )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(val_seqs.to(device), val_rc.to(device)).cpu()\n",
    "            val_loss = criterion(val_pred, val_expression)\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_pearson = pearsonr(val_expression, val_pred)\n",
    "            val_spearman = spearmanr(val_expression, val_pred)\n",
    "\n",
    "        # store model iff on a cuda environment and if the repo is clean\n",
    "        if device.type == \"cuda\" and sha:\n",
    "            torch.save(model.state_dict(), here(f\"results/models/{model_name}.pt\"))\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"commit\": sha,\n",
    "                    \"train_loss\": tr_losses,\n",
    "                    \"train_pearson\": tr_pearson,\n",
    "                    \"train_spearman\": tr_spearman,\n",
    "                    \"val_loss\": val_losses,\n",
    "                    \"val_pearson\": val_pearson,\n",
    "                    \"val_spearman\": val_spearman,\n",
    "                },\n",
    "                here(f\"results/models/{model_name}_stats.pt\"),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6aed7-13e9-4f48-a00a-f051b570e208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if device.type == \"cuda\" and sha:\n",
    "    with (open(here(\"results/models/summary.tsv\"), \"a\")) as S:\n",
    "        S.write(\n",
    "            f\"{model_name}\\t{tr_pearson:.3f}\\t{tr_spearman:.3f}\\t{val_pearson:.3f}\\t{val_spearman:.3f}\\t{sha}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14adb51-74b9-4c88-82dd-40f0af4a2867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
    "sns.lineplot(x=list(range(len(tr_losses))), y=tr_losses)\n",
    "sns.lineplot(\n",
    "    x=[(i + 1) * len(tr_loader) for i in range(len(val_losses))],\n",
    "    y=val_losses,\n",
    "    color=\"orange\",\n",
    ")\n",
    "ax.set(xlabel=\"Minibatch\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b26f7d-3189-4aec-9d49-0ba3893b6e9c",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba496d8c-074a-46aa-949e-fe02fd60b2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "model = model_obj().to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load(here(f\"results/models/{model_name}.pt\"), map_location=device)\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    global embedding\n",
    "    embedding = output\n",
    "\n",
    "\n",
    "hook = model.fc[-2].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # training predictions\n",
    "    tr_seqs, tr_rc, tr_expression = next(iter(tr_loader))\n",
    "    tr_pred = model(tr_seqs.to(device), tr_rc.to(device)).cpu()\n",
    "    tr_embedding = embedding\n",
    "\n",
    "    # validation predictions\n",
    "    val_pred = model(val_seqs.to(device), val_rc.to(device)).cpu()\n",
    "    val_embedding = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b15a1b-1837-42f5-b00f-0b0f482b7baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def umap(x, y, **sns_kwargs):\n",
    "\n",
    "    x = numpify(x)\n",
    "    y = numpify(y).flatten()\n",
    "    x_emb = UMAP().fit_transform(x)\n",
    "\n",
    "    sns.set_theme()\n",
    "    g = sns.scatterplot(x=x_emb[:, 0], y=x_emb[:, 1], hue=y, **sns_kwargs)\n",
    "    g.set(xlabel=\"UMAP 1\", ylabel=\"UMAP 2\")\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 15, 6\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "g = umap(tr_embedding, tr_expression, ax=ax[0])\n",
    "g.set_title(\"Train\")\n",
    "g = umap(val_embedding, val_expression, ax=ax[1])\n",
    "g.set_title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0aaeb0-6862-457b-a152-49014f3c508c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plt_predictions(y, y_pred, split):\n",
    "\n",
    "    y = numpify(y).flatten()\n",
    "    y_pred = numpify(y_pred).flatten()\n",
    "    axis = 0 if split == \"Train\" else 1\n",
    "\n",
    "    g = sns.scatterplot(x=y, y=y_pred, ax=ax[axis])\n",
    "    g.set(xlabel=\"y\", ylabel=\"y_pred\")\n",
    "    g.set_title(split)\n",
    "    ax[axis].axline([0, 0], [17, 17], color=\"red\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "plt_predictions(tr_expression, tr_pred, \"Train\")\n",
    "plt_predictions(val_expression, val_pred, \"Validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
