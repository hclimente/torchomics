{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d46d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from random import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from git import Repo\n",
    "from pyprojroot import here\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from umap import UMAP\n",
    "\n",
    "from data import Dream, load\n",
    "from models import ResNet, fix_seeds\n",
    "from models.utils import init_weights, numpify, pearsonr, spearmanr\n",
    "\n",
    "# save the current commit hash iff the repo has no un-committed changes\n",
    "repo = Repo(search_parent_directories=True)\n",
    "sha = None if repo.is_dirty() else repo.head.object.hexsha\n",
    "\n",
    "if not sha:\n",
    "    warnings.warn(\"Uncommitted changes. The model parameters won't be saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48757f0e",
   "metadata": {},
   "source": [
    "# Model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6fdcc",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "model_obj = ResNet\n",
    "n_epochs = 10\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "seed = 0\n",
    "\n",
    "# data transforms\n",
    "rc_transform = False\n",
    "\n",
    "fix_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fec82f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model specification\n",
    "model = model_obj().to(device)\n",
    "model_name = f\"{model.__class__.__name__}_epochs={n_epochs}_batch={batch_size}\"\n",
    "\n",
    "print(summary(model))\n",
    "\n",
    "# initialise model weights\n",
    "model.apply(init_weights)\n",
    "\n",
    "# initialize last layer's bias to the average\n",
    "with torch.no_grad():\n",
    "    model.fc[-1].bias[0] = torch.tensor(11.147).to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61f04d",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6602be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and validation\n",
    "val_size = 10000\n",
    "\n",
    "tr_cached = \"train_dev.pt\" if device.type == \"cpu\" else \"train.pt\"\n",
    "tr = load(\"train_sequences.txt\", tr_cached, Dream, path=here(\"data/dream\"))\n",
    "tr.cache_rc()\n",
    "tr, val = torch.utils.data.random_split(tr, [len(tr) - val_size, val_size])\n",
    "\n",
    "val_loader = DataLoader(val, batch_size=val_size)\n",
    "val_seqs, val_rc, val_expression = next(iter(val_loader))\n",
    "\n",
    "# test (unlabelled)\n",
    "te = load(\"test_sequences.txt\", \"test.pt\", Dream, path=here(\"data/dream\"))\n",
    "te.cache_rc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b26b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data transformations\n",
    "tf = []\n",
    "\n",
    "if rc_transform:\n",
    "    model_name += \"_t=rc\"\n",
    "\n",
    "tr.transforms = transforms.Compose(tf)\n",
    "tr_loader = DataLoader(tr, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fa16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create a smaller training set for development\n",
    "# tr = load(\"train_sequences.txt\", \"train.pt\", Dream, path=here(\"data/dream\"))\n",
    "# tr.cache_rc()\n",
    "# tr, val = torch.utils.data.random_split(tr, [len(tr) - val_size, val_size])\n",
    "\n",
    "# d = Dream(torch.Tensor(), torch.Tensor())\n",
    "# d.sequences, d.rc_sequences, d.expression = next(\n",
    "#     iter(DataLoader(tr, batch_size=100000 + val_size, shuffle=True))\n",
    "# )\n",
    "# d.expression = d.expression.flatten()\n",
    "\n",
    "# torch.save(d, here(\"data/dream/train_dev.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f92c1",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ee0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_losses = []\n",
    "tr_pearson_list = []\n",
    "tr_spearman_list = []\n",
    "val_losses = []\n",
    "val_pearson_list = []\n",
    "val_spearman_list = []\n",
    "tr_pearson = 0\n",
    "tr_spearman = 0\n",
    "best_performance = -float(\"inf\")\n",
    "\n",
    "# scaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    with tqdm(tr_loader) as tepoch:\n",
    "        for seq, rc, y in tepoch:\n",
    "\n",
    "            # forward\n",
    "            model.train()\n",
    "\n",
    "            seq, rc, y = seq.to(device), rc.to(device), y.to(device)\n",
    "\n",
    "            if rc_transform and random() < 0.5:\n",
    "                seq, rc = rc, seq\n",
    "\n",
    "            with torch.autocast(device_type=device.type):  # mixed precision\n",
    "                y_pred = model(seq, rc)\n",
    "                tr_loss = criterion(y_pred, y)\n",
    "\n",
    "            # backward (with mixed precision)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(tr_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # evaluation\n",
    "            model.eval()\n",
    "\n",
    "            tr_losses.append(tr_loss.item())\n",
    "            tr_pearson = 0.9 * tr_pearson + 0.1 * pearsonr(y, y_pred)\n",
    "            tr_spearman = 0.9 * tr_spearman + 0.1 * spearmanr(y, y_pred)\n",
    "\n",
    "            tepoch.set_postfix(\n",
    "                tr_loss=tr_loss.item(),\n",
    "                r=tr_pearson,\n",
    "                rho=tr_spearman,\n",
    "            )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tr_pearson_list.append(tr_pearson)\n",
    "            tr_spearman_list.append(tr_spearman)\n",
    "            val_pred = model(val_seqs.to(device), val_rc.to(device)).cpu()\n",
    "            val_loss = criterion(val_pred, val_expression)\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_pearson = pearsonr(val_expression, val_pred)\n",
    "            val_pearson_list.append(val_pearson)\n",
    "            val_spearman = spearmanr(val_expression, val_pred)\n",
    "            val_spearman_list.append(val_spearman)\n",
    "\n",
    "        # store model iff on a cuda environment and if the repo is clean\n",
    "        performance = val_pearson + val_spearman\n",
    "\n",
    "        if device.type == \"cuda\" and sha and performance > best_performance:\n",
    "\n",
    "            best_performance = performance\n",
    "            torch.save(model.state_dict(), here(f\"results/models/{model_name}.pt\"))\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"commit\": sha,\n",
    "                    \"train_loss\": tr_losses,\n",
    "                    \"train_pearson\": tr_pearson,\n",
    "                    \"train_spearman\": tr_spearman,\n",
    "                    \"val_loss\": val_losses,\n",
    "                    \"val_pearson\": val_pearson,\n",
    "                    \"val_spearman\": val_spearman,\n",
    "                },\n",
    "                here(f\"results/models/{model_name}_stats.pt\"),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac94df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if device.type == \"cuda\" and sha:\n",
    "    # Best mean of pearson and spearman\n",
    "    best_epoch = torch.argmax(\n",
    "        torch.Tensor(val_pearson_list) + torch.Tensor(val_spearman_list)\n",
    "    )\n",
    "\n",
    "    tr_pearson = tr_pearson_list[best_epoch]\n",
    "    tr_spearman = tr_spearman_list[best_epoch]\n",
    "    val_pearson = val_pearson_list[best_epoch]\n",
    "    val_spearman = val_spearman_list[best_epoch]\n",
    "\n",
    "    with (open(here(\"results/models/summary.tsv\"), \"a\")) as S:\n",
    "        S.write(f\"{model_name}\\t{tr_pearson:.3f}\\t{tr_spearman:.3f}\\t\")\n",
    "        S.write(f\"{val_pearson:.3f}\\t{val_spearman:.3f}\\t{sha}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9c04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
    "sns.lineplot(x=list(range(len(tr_losses))), y=tr_losses)\n",
    "sns.lineplot(\n",
    "    x=[(i + 1) * len(tr_loader) for i in range(len(val_losses))],\n",
    "    y=val_losses,\n",
    "    color=\"orange\",\n",
    ")\n",
    "ax.set(xlabel=\"Minibatch\", ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4ab2d",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adf64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "model = model_obj().to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load(here(f\"results/models/{model_name}.pt\"), map_location=device)\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    global embedding\n",
    "    embedding = output\n",
    "\n",
    "\n",
    "hook = model.fc[-2].register_forward_hook(hook_fn)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # training predictions\n",
    "    tr_seqs, tr_rc, tr_expression = next(iter(tr_loader))\n",
    "    tr_pred = model(tr_seqs.to(device), tr_rc.to(device)).cpu()\n",
    "    tr_embedding = embedding\n",
    "\n",
    "    # validation predictions\n",
    "    val_pred = model(val_seqs.to(device), val_rc.to(device)).cpu()\n",
    "    val_embedding = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757fbe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def umap(x, y, **sns_kwargs):\n",
    "\n",
    "    x = numpify(x)\n",
    "    y = numpify(y).flatten()\n",
    "    x_emb = UMAP().fit_transform(x)\n",
    "\n",
    "    sns.set_theme()\n",
    "    g = sns.scatterplot(x=x_emb[:, 0], y=x_emb[:, 1], hue=y, **sns_kwargs)\n",
    "    g.set(xlabel=\"UMAP 1\", ylabel=\"UMAP 2\")\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = 15, 6\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "g = umap(tr_embedding, tr_expression, ax=ax[0])\n",
    "g.set_title(\"Train\")\n",
    "g = umap(val_embedding, val_expression, ax=ax[1])\n",
    "g.set_title(\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab793d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plt_predictions(y, y_pred, split):\n",
    "\n",
    "    y = numpify(y).flatten()\n",
    "    y_pred = numpify(y_pred).flatten()\n",
    "    axis = 0 if split == \"Train\" else 1\n",
    "\n",
    "    g = sns.scatterplot(x=y, y=y_pred, ax=ax[axis])\n",
    "    g.set(xlabel=\"y\", ylabel=\"y_pred\")\n",
    "    g.set_title(split)\n",
    "    ax[axis].axline([0, 0], [17, 17], color=\"red\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "plt_predictions(tr_expression, tr_pred, \"Train\")\n",
    "plt_predictions(val_expression, val_pred, \"Validation\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "auto:light,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
